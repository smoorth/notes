# PostgreSQL pgvector: Comprehensive Guide

## Table of Contents

- [Introduction](#introduction)
- [Installation](#installation)
- [Vector Basics](#vector-basics)
- [Creating and Managing Vector Data](#creating-and-managing-vector-data)
- [Similarity Search Operations](#similarity-search-operations)
- [Indexing Strategies](#indexing-strategies)
- [Performance Optimization](#performance-optimization)
- [Common Use Cases](#common-use-cases)
- [Advanced Techniques](#advanced-techniques)
- [Troubleshooting](#troubleshooting)

## Introduction

pgvector is an extension for PostgreSQL that adds support for vector operations, enabling similarity search, recommendations, and AI-driven applications directly within your PostgreSQL database. It allows storing embeddings from machine learning models and performing fast nearest-neighbor searches.

### What are Vector Embeddings?

Vector embeddings are numerical representations of data (text, images, audio, etc.) where semantic similarity is captured by proximity in vector space. These are typically generated by machine learning models like:

- Text embeddings (BERT, GPT, Sentence Transformers)
- Image embeddings (ResNet, EfficientNet)
- Audio embeddings (wav2vec)

## Installation

### Prerequisites

- PostgreSQL 11 or later
- Administrative access to your database

### Install from Source

```bash
git clone https://github.com/pgvector/pgvector.git
cd pgvector
make
make install
```

### Install using Extensions

On systems with PostgreSQL packages that include pgvector:

```bash
sudo apt install postgresql-15-pgvector  # For Ubuntu/Debian
```

### Enable in Database

```sql
CREATE EXTENSION vector;
```

## Vector Basics

### The Vector Data Type

pgvector introduces a new data type called `vector` which represents a fixed-length array of float values:

```sql
-- Create a table with a 3-dimensional vector column
CREATE TABLE items (
    id SERIAL PRIMARY KEY,
    embedding VECTOR(3)  -- 3-dimensional vector
);

-- Insert data
INSERT INTO items (embedding) VALUES ('[1.0, 2.0, 3.0]');
```

### Vector Dimensions

The dimension is specified when creating tables and must be consistent. Common dimension sizes:

- OpenAI text-embedding-ada-002: 1536 dimensions
- CLIP image embeddings: 512 dimensions
- BERT embeddings: 768 dimensions

## Creating and Managing Vector Data

### Creating Tables with Vector Columns

```sql
CREATE TABLE documents (
    id SERIAL PRIMARY KEY,
    content TEXT,
    embedding VECTOR(1536)  -- For storing OpenAI embeddings
);
```

### Inserting Vector Data

```sql
-- Single insert
INSERT INTO documents (content, embedding) VALUES
('PostgreSQL documentation', '[0.1, 0.2, ..., 0.5]');

-- Batch insert
INSERT INTO documents (content, embedding)
SELECT
    content,
    embedding::vector
FROM
    json_table;
```

### Updating Vector Data

```sql
UPDATE documents
SET embedding = '[0.2, 0.3, ..., 0.6]'
WHERE id = 1;
```

## Similarity Search Operations

### Distance Metrics

pgvector supports three distance metrics:

1. **Euclidean Distance (`<->`)** - Linear/straight-line distance

   ```sql
   SELECT * FROM items ORDER BY embedding <-> '[1.0, 2.0, 3.0]' LIMIT 5;
   ```

2. **Cosine Distance (`<=>`)** - Measures angle difference, normalized for magnitude

   ```sql
   SELECT * FROM items ORDER BY embedding <=> '[1.0, 2.0, 3.0]' LIMIT 5;
   ```

3. **Inner Product (`<#>`)** - For when vectors are already normalized

   ```sql
   SELECT * FROM items ORDER BY embedding <#> '[1.0, 2.0, 3.0]' LIMIT 5;
   ```

### K-Nearest Neighbors (KNN) Search

```sql
-- Find 10 most similar documents to a query
SELECT id, content, embedding <-> '[0.1, 0.2, ..., 0.5]' as distance
FROM documents
ORDER BY distance
LIMIT 10;
```

### Filtering with Vector Search

```sql
-- Filtered vector search
SELECT id, content, embedding <-> '[0.1, 0.2, ..., 0.5]' as distance
FROM documents
WHERE category = 'technology' AND created_at > '2023-01-01'
ORDER BY distance
LIMIT 10;
```

## Indexing Strategies

### HNSW Index (Hierarchical Navigable Small World)

Best for approximate nearest neighbor search with excellent recall/performance tradeoff:

```sql
-- Create HNSW index
CREATE INDEX ON documents USING hnsw (embedding vector_cosine_ops) WITH (m = 16, ef_construction = 64);
```

Parameters:

- `m`: Maximum number of connections (default: 16)
- `ef_construction`: Size of the dynamic candidate list (default: 64)
- Higher values improve recall but slow down indexing

### IVFFlat Index (Inverted File with Flat Compression)

Good for larger datasets:

```sql
-- Create IVFFlat index
CREATE INDEX ON documents USING ivfflat (embedding vector_l2_ops) WITH (lists = 100);
```

Parameters:

- `lists`: Number of partition lists (ideally 10 Ã— sqrt(row_count))

### Choosing the Right Index

- **HNSW**: Better recall, faster queries, more memory
- **IVFFlat**: Less memory, faster build time, requires tuning

## Performance Optimization

### Tuning Query Parameters

For IVFFlat index, adjust probes:

```sql
SET ivfflat.probes = 10;  -- Higher means better recall but slower queries
```

For HNSW index, adjust ef_search:

```sql
SET hnsw.ef_search = 100;  -- Higher means better recall but slower queries
```

### Monitoring Performance

```sql
EXPLAIN ANALYZE SELECT * FROM documents
ORDER BY embedding <-> '[0.1, 0.2, ..., 0.5]'
LIMIT 10;
```

### Optimizing Large Vectors

For high-dimensional vectors:

- Consider dimensionality reduction techniques (PCA, UMAP)
- Split indexing and search across multiple servers

## Common Use Cases

### Semantic Text Search

```sql
-- Create embeddings table
CREATE TABLE articles (
    id SERIAL PRIMARY KEY,
    title TEXT,
    content TEXT,
    embedding VECTOR(1536)
);

-- Find articles similar to a search query
SELECT title, content
FROM articles
ORDER BY embedding <=> '<embedding of search query>'
LIMIT 5;
```

### Recommendation Systems

```sql
-- Find products similar to what a user has viewed
SELECT p.id, p.name, p.description
FROM products p
WHERE p.id != :viewed_product_id
ORDER BY p.embedding <-> (SELECT embedding FROM products WHERE id = :viewed_product_id)
LIMIT 5;
```

### Image Similarity Search

```sql
-- Create table for images
CREATE TABLE images (
    id SERIAL PRIMARY KEY,
    path TEXT,
    metadata JSONB,
    embedding VECTOR(512)  -- CLIP embeddings
);

-- Find visually similar images
SELECT path, metadata
FROM images
ORDER BY embedding <-> :query_embedding
LIMIT 10;
```

### Hybrid Search (Text + Vector)

```sql
-- Combine full-text and vector search
SELECT id, title, content,
       ts_rank(to_tsvector('english', content), query) * 0.3 +
       (1 - (embedding <=> :query_embedding)) * 0.7 as score
FROM articles,
     plainto_tsquery('english', :text_query) query
WHERE to_tsvector('english', content) @@ query
ORDER BY score DESC
LIMIT 10;
```

## Advanced Techniques

### Vector Quantization

For very large datasets, consider quantizing vectors:

```sql
-- Store 16-bit quantized vectors
CREATE TABLE compressed_vectors (
    id SERIAL PRIMARY KEY,
    original_id INTEGER REFERENCES documents(id),
    quantized_embedding BYTEA  -- Store quantized vectors as binary
);
```

### Batched Operations

For bulk processing:

```sql
-- Batch insert with unnest
INSERT INTO embeddings (item_id, embedding)
SELECT u.id, u.embedding::vector
FROM unnest(
    ARRAY[1, 2, 3],  -- IDs
    ARRAY['[0.1,0.2,0.3]', '[0.4,0.5,0.6]', '[0.7,0.8,0.9]']  -- Embeddings
) AS u(id, embedding);
```

### Working with External AI Services

```python
# Example using Python with OpenAI and psycopg
import openai
import psycopg
import numpy as np

# Generate embedding
response = openai.Embedding.create(
    input="Document content here",
    model="text-embedding-ada-002"
)
embedding = response['data'][0]['embedding']

# Insert into PostgreSQL
with psycopg.connect("dbname=mydb") as conn:
    with conn.cursor() as cur:
        cur.execute(
            "INSERT INTO documents (content, embedding) VALUES (%s, %s)",
            ("Document content here", str(embedding))
        )
```

## Troubleshooting

### Common Issues

#### Index Not Being Used

If EXPLAIN shows sequential scan instead of index scan:

- Check if your index matches the distance operator (<->, <=>, <#>)
- For IVFFlat, ensure dataset is large enough to benefit from indexing
- Try increasing `ivfflat.probes` or `hnsw.ef_search`

#### Poor Recall Quality

- Try different distance metrics based on your data
- Increase `ef_search` for HNSW or `probes` for IVFFlat
- Consider using exact search for small datasets

#### Memory Issues

- Reduce vector dimensions if possible
- For IVFFlat, decrease `lists` parameter
- For HNSW, decrease `m` parameter
- Consider partitioning very large tables

### Performance Benchmarking

```sql
-- Simple benchmark for search speed
\timing on
SELECT count(*)
FROM (
    SELECT id FROM documents
    ORDER BY embedding <-> '[0.1, 0.2, ..., 0.5]'
    LIMIT 100
) t;
\timing off
```

---

## Additional Resources

- [Official pgvector Documentation](https://github.com/pgvector/pgvector)
- [PostgreSQL Documentation](https://www.postgresql.org/docs/)
- [Vector Database Benchmarks](https://ann-benchmarks.com/)
- [Application examples with pgvector](https://github.com/pgvector/pgvector/tree/master/examples)
